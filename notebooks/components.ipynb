{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components Notebook\n",
    "The purpose of this notebook is to locally test the individual pipeline components before running the pipelines in google cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.cloud.aiplatform as vertex_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCP_PROJECT_ID = \"jokes\"\n",
    "GCP_REGION = \"northamerica-northeast1\"\n",
    "GCP_STORAGE_BUCKET = \"gs://vertex_ai_experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    project=GCP_PROJECT_ID,\n",
    "    location=GCP_REGION,\n",
    "    staging_bucket=GCP_STORAGE_BUCKET\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline Components\n",
    "1. Build Training Image\n",
    "2. Data Preperation\n",
    "3. Model Training\n",
    "\n",
    "### Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set required input parameters for running the component\n",
    "DATASET_NAME = 'CIFAR10'\n",
    "TRAIN_PATH = './data/train'\n",
    "TEST_PATH = './data/test'\n",
    "DOWNLOAD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/Resources/Python.app/Contents/MacOS/Python: can't open file '/Users/tristano/Desktop/implementations/ViT/notebooks/./pipeline/training/data_prep/task_data_prep.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! python3 ./pipeline/training/data_prep/task_data_prep.py \\\n",
    "--dataset_name $DATASET_NAME \\\n",
    "--train_path $TRAIN_PATH \\\n",
    "--test_path $TEST_PATH \\\n",
    "--download $DOWNLOAD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"vit\"\n",
    "EXPERIMENT_NAME = \"vit-experiment\"\n",
    "DEVICE = \"cpu\"\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "WORKERS = 1\n",
    "LEARNING_RATE = 0.01\n",
    "DECAY = 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 ./pipeline/training/model_training/task_train_model.py \\\n",
    "--model_name $MODEL_NAME \\\n",
    "--experiment_name $EXPERIMENT_NAME \\\n",
    "--device $DEVICE \\\n",
    "--epochs $EPOCHS "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline - Steps\n",
    "1. Build serving image\n",
    "2. Model Upload: registers model in Vertex AI\n",
    "3. Create Endpoint: creates a Vertex AI endpoint\n",
    "4. Model Deploy: deploys model to endpoint\n",
    "\n",
    "## Build Serving Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVING_IMAGE_REPO = \"vit-inference\"\n",
    "SERVING_IMAGE_TAG = \"latest\"\n",
    "SERVING_IMAGE_URI = f\"{GCP_REGION}-docker.pkg.dev/{GCP_PROJECT_ID}/{SERVING_IMAGE_REPO}/{SERVING_IMAGE_TAG}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker build -t $SERVING_IMAGE_URI -f ./dockerfiles/inference/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker push $SERVING_IMAGE_URI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ARTIFACT_URI = \"gs://training-pipeline/model\"\n",
    "HEALTH_ROUTE = \"/ping\"\n",
    "PREDICT_ROUTE = f\"/predictions/{MODEL_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 ./pipeline/inference/model_upload/run_model_upload_task.py \\\n",
    "--model_display_name $MODEL_NAME \\\n",
    "--model_artifact_uri $MODEL_ARTIFACT_URI \\\n",
    "--serving_image_uri $SERVING_IMAGE_URI \\\n",
    "--health_route $HEALTH_ROUTE \\\n",
    "--predict_route $PREDICT_ROUTE "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT_DISPLAY_NAME = \"vit-endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 ./pipeline/inference/endpoint/endpoint_create.py \\\n",
    "--endpoint_display_name $ENDPOINT_DISPLAY_NAME"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact = vertex_ai.Model()\n",
    "machine_type = \"n1-standard-2\"\n",
    "accelerator_type = \"ACCELERATOR_TYPE_UNSPECIFIED\"\n",
    "accelerator_count = \"0\"\n",
    "traffic_percentage = \"100\"\n",
    "autoscaling_nodes_min = \"1\"\n",
    "autoscaling_nodes_max = \"1\"\n",
    "autoscaling_cpu_utilization = \"60\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = vertex_ai.Endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.deploy(\n",
    "    model=model_artifact,\n",
    "    deployed_model_display_name=MODEL_NAME,\n",
    "    machine_type=machine_type,\n",
    "    accelerator_type=accelerator_type,\n",
    "    accelerator_count=accelerator_count,\n",
    "    traffic_percentage=traffic_percentage,\n",
    "    min_replica_count=autoscaling_nodes_min,\n",
    "    max_replica_count=autoscaling_nodes_max,\n",
    "    autoscaling_target_cpu_utilization=autoscaling_cpu_utilization\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
